{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-10T01:06:29.783455Z",
     "start_time": "2024-01-10T01:06:29.700639Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-10T01:45:06.770005Z",
     "start_time": "2024-01-10T01:45:05.685213Z"
    }
   },
   "outputs": [],
   "source": [
    "from src import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-10T01:45:07.043161Z",
     "start_time": "2024-01-10T01:45:06.770230Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from collections import defaultdict\n",
    "from tqdm.auto import tqdm, trange\n",
    "import pickle as pkl\n",
    "from typing import Literal, get_type_hints\n",
    "\n",
    "import itertools as it\n",
    "import more_itertools as mit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-10T01:45:07.047452Z",
     "start_time": "2024-01-10T01:45:07.043874Z"
    }
   },
   "outputs": [],
   "source": [
    "def player_formatter(player: int) -> str:\n",
    "    symbol_mapping = {0: \" \", 1: \"X\", -1: \"O\"}\n",
    "    return symbol_mapping[player]\n",
    "    \n",
    "def state_formatter(state: tuple[int, ...]) -> str:\n",
    "    size = int(len(state) ** 0.5)\n",
    "    formatted_state = \"\\n\"\n",
    "    for i in range(size):\n",
    "        formatted_state += \"+---+---+---+\\n\"\n",
    "        row = state[i*size:(i+1)*size]\n",
    "        formatted_state += \"| \" + \" | \".join(player_formatter(cell)for cell in row) + \" |\\n\"\n",
    "    formatted_state += \"+---+---+---+\"\n",
    "    return formatted_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "+---+---+---+\n",
      "|   |   |   |\n",
      "+---+---+---+\n",
      "|   |   |   |\n",
      "+---+---+---+\n",
      "|   |   |   |\n",
      "+---+---+---+\n"
     ]
    }
   ],
   "source": [
    "ttt = TicTacToe(default_state_formatter=state_formatter)\n",
    "ttt.render()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-10T01:45:08.348852Z",
     "start_time": "2024-01-10T01:45:08.339646Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "q_table_policy = QTablePolicy.load('q_table', lr=0.1, name='Deterministic Q Table')\n",
    "q_table_policy_stochastic = QTablePolicy(q_table_policy.q_table, \n",
    "                                         lr=0.1,\n",
    "                                         stochastic=True,\n",
    "                                         temperature=0.5,\n",
    "                                         name='Stochastic Q Table')\n",
    "human_policy = PromptPolicy(player_formatter)\n",
    "min_max_policy = MinMaxPolicy(game_cls=TicTacToe)\n",
    "mcts_policy = MCTS(game_cls=TicTacToe)\n",
    "# q_table_policy = QTablePolicy(lr=0.1)\n",
    "# mlp_policy = MLPPolicy(Model(), lr=0.001)\n",
    "# mcts_policy = MCTS(ttt)\n",
    "# mlp_policy = MLPPolicy.load(Model(), 'mlp.pt', lr=0.001)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-10T01:45:08.974650Z",
     "start_time": "2024-01-10T01:45:08.920532Z"
    }
   }
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class MCTS in module src.policies.q_policies.mcts_policy:\n",
      "\n",
      "class MCTS(src.policies.q_policies.base_q_policy.BaseQPolicySingle)\n",
      " |  MCTS(game_cls, *args, **kwargs)\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      MCTS\n",
      " |      src.policies.q_policies.base_q_policy.BaseQPolicySingle\n",
      " |      src.policies.q_policies.base_q_policy.BaseQPolicy\n",
      " |      src.policies.base_policy.BasePolicy\n",
      " |      abc.ABC\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, game_cls, *args, **kwargs)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  back_propogate(self, node, reward)\n",
      " |  \n",
      " |  calculate_reward(self, node)\n",
      " |  \n",
      " |  execute_round(self)\n",
      " |      execute a selection-expansion-simulation-backpropagation round\n",
      " |  \n",
      " |  expand(self, node)\n",
      " |  \n",
      " |  find_node_matching_state(self, node, state)\n",
      " |  \n",
      " |  get_all_Qs(self, state: tuple[int, ...], player: int, action_space: set[int]) -> dict[int, float]\n",
      " |  \n",
      " |  get_best_move(self, node, exploration_constant)\n",
      " |  \n",
      " |  select_child(self, node)\n",
      " |  \n",
      " |  simulate_by_brute_force(self, node)\n",
      " |  \n",
      " |  simulate_by_sampling(self, node)\n",
      " |  \n",
      " |  simulated_game(self, node)\n",
      " |  \n",
      " |  update_Q(self, state: tuple[int, ...], player: int, action: int, Q: float) -> None\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from src.policies.q_policies.base_q_policy.BaseQPolicySingle:\n",
      " |  \n",
      " |  batch_get_all_Qs(self, states: list[tuple[int, ...]], players: list[int], action_spaces: list[set[int]]) -> list[dict[int, float]]\n",
      " |  \n",
      " |  batch_update_Q(self, states: list[tuple[int, ...]], players: list[int], actions: list[int], Qs: list[float]) -> float\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from src.policies.q_policies.base_q_policy.BaseQPolicy:\n",
      " |  \n",
      " |  __call__(self, state: tuple[int, ...], player: int, action_space: set[int]) -> int\n",
      " |      Call self as a function.\n",
      " |  \n",
      " |  batch_get_Q(self, states: list[tuple[int, ...]], players: list[int], actions: list[int]) -> list[float]\n",
      " |  \n",
      " |  get_Q(self, state: tuple[int, ...], player: int, action: int) -> float\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from src.policies.base_policy.BasePolicy:\n",
      " |  \n",
      " |  get_name(self) -> str\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from src.policies.base_policy.BasePolicy:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n"
     ]
    }
   ],
   "source": [
    "help(MCTS)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-10T01:45:10.162969Z",
     "start_time": "2024-01-10T01:45:10.153638Z"
    }
   },
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-10T01:45:10.609092Z",
     "start_time": "2024-01-10T01:45:10.606352Z"
    }
   },
   "outputs": [],
   "source": [
    "def play(ttt, policy=None, print_state=False):\n",
    "    if policy is None:\n",
    "        policy = RandomPolicy()\n",
    "    if not isinstance(policy, dict):\n",
    "        policy = {-1: policy, 1: policy}\n",
    "\n",
    "    tape = [dict(\n",
    "        player=None,\n",
    "        action_space=None,\n",
    "        action=None,\n",
    "        state=ttt.get_state(),\n",
    "        winner=0\n",
    "    )]\n",
    "\n",
    "    while (action_space := ttt.get_actions()) and not ttt.get_winner():\n",
    "        if print_state:\n",
    "            ttt.render()\n",
    "        player = ttt.player\n",
    "        action = ttt.agent_move(policy[player])\n",
    "        state = ttt.get_state()\n",
    "        winner = ttt.get_winner()\n",
    "        tape.append(dict(\n",
    "            player=player,\n",
    "            action_space=action_space,\n",
    "            action=action,\n",
    "            state=state,\n",
    "            winner=winner\n",
    "        ))\n",
    "    if print_state:\n",
    "        ttt.render()\n",
    "\n",
    "    tape.append(dict(\n",
    "        player=None,\n",
    "        action_space=set(),\n",
    "        action=None,\n",
    "        state=ttt.get_state(),\n",
    "        winner=ttt.get_winner()\n",
    "    ))\n",
    "    \n",
    "    return tape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-10T01:45:10.925817Z",
     "start_time": "2024-01-10T01:45:10.921075Z"
    }
   },
   "outputs": [],
   "source": [
    "def swap(state: np.ndarray, option: Literal[1, -1]):\n",
    "    return option * state\n",
    "\n",
    "def flip(state: np.ndarray, option: Literal[True, False]):\n",
    "    return np.fliplr(state) if option else state\n",
    "\n",
    "def rotate(state: np.ndarray, option: Literal[0, 1, 2, 3]):\n",
    "    return np.rot90(state, k=option)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-10T01:45:11.234638Z",
     "start_time": "2024-01-10T01:45:11.231070Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_param_options(fn, param='option'):\n",
    "    return get_type_hints(fn)['option'].__args__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-10T01:45:11.575837Z",
     "start_time": "2024-01-10T01:45:11.571667Z"
    }
   },
   "outputs": [],
   "source": [
    "def transform_state(raw_state, fns, opts):\n",
    "    state = raw_state.reshape([3, 3])\n",
    "    for fn, opt in zip(fns, opts):\n",
    "        state = fn(state, opt)\n",
    "    return state.flatten()\n",
    "\n",
    "def transform_actions(raw_actions, fns, opts):\n",
    "    actions = np.zeros(9)\n",
    "    actions[raw_actions] = 1\n",
    "    actions = transform_state(actions, fns, opts)\n",
    "    return np.nonzero(actions)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-10T01:45:11.963222Z",
     "start_time": "2024-01-10T01:45:11.956867Z"
    }
   },
   "outputs": [],
   "source": [
    "def bellman_equation(policy, reward, state, player, actions):\n",
    "    if not actions:\n",
    "        return reward\n",
    "    return reward + max(policy.get_Q(state, player, action) for action in actions)\n",
    "\n",
    "def replay_episode(tape, policy):\n",
    "    state_list, player_list, action_list, q_list = [], [], [], []\n",
    "    transformations = [swap, flip, rotate]\n",
    "\n",
    "    for pre, cur, nxt in mit.windowed(tape, 3):\n",
    "        raw_start_state = np.array(list(pre['state'])).astype(int)\n",
    "        raw_end_state = np.array(list(nxt['state'])).astype(int)\n",
    "        raw_action = np.array([cur['action']]).astype(int)\n",
    "        raw_action_space = np.array(list(nxt['action_space'])).astype(int)\n",
    "        player = cur['player']\n",
    "        reward = cur['player'] * nxt['winner']\n",
    "        \n",
    "        for opts in it.product(*map(get_param_options, transformations)):\n",
    "            start_state = tuple(transform_state(raw_start_state, transformations, opts).tolist())\n",
    "            end_state = tuple(transform_state(raw_end_state, transformations, opts).tolist())\n",
    "            action = transform_actions(raw_action, transformations, opts).item()\n",
    "            action_space = set(transform_actions(raw_action_space, transformations, opts).tolist())\n",
    "\n",
    "            new_q = bellman_equation(policy, reward, end_state, player, action_space)\n",
    "            state_list.append(start_state)\n",
    "            player_list.append(player)\n",
    "            action_list.append(action)\n",
    "            q_list.append(new_q)\n",
    "\n",
    "    return state_list, player_list, action_list, q_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-10T01:23:01.902269Z",
     "start_time": "2024-01-10T01:23:01.896340Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(policy, episodes, epsilon=0.1):\n",
    "    eps_greedy_policy = EpsilonGreedyPolicy(policy, epsilon=epsilon)\n",
    "    for episode in trange(episodes):\n",
    "        ttt.reset(start_player=random.choice([1, -1]))\n",
    "        tape = play(ttt, policy=eps_greedy_policy)\n",
    "        state_list, player_list, action_list, q_list = replay_episode(tape, policy)\n",
    "        loss = policy.batch_update_Q(state_list, player_list, action_list, q_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-01T07:43:08.744838Z",
     "start_time": "2024-01-01T07:33:10.139453Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/100000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b6ba562d87124d4d8672f969a2c35fee"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train(q_table_policy_stochastic, episodes=100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Manual Play"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T03:07:56.559410Z",
     "start_time": "2024-01-03T03:07:56.462213Z"
    }
   },
   "outputs": [],
   "source": [
    "q_table_policy.save('q_table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "+---+---+---+\n",
      "|   |   |   |\n",
      "+---+---+---+\n",
      "|   |   |   |\n",
      "+---+---+---+\n",
      "|   |   |   |\n",
      "+---+---+---+\n",
      "\n",
      "+---+---+---+\n",
      "|   |   |   |\n",
      "+---+---+---+\n",
      "|   | X |   |\n",
      "+---+---+---+\n",
      "|   |   |   |\n",
      "+---+---+---+\n",
      "\n",
      "+---+---+---+\n",
      "|   |   |   |\n",
      "+---+---+---+\n",
      "|   | X |   |\n",
      "+---+---+---+\n",
      "|   |   | O |\n",
      "+---+---+---+\n",
      "\n",
      "+---+---+---+\n",
      "|   |   |   |\n",
      "+---+---+---+\n",
      "|   | X | X |\n",
      "+---+---+---+\n",
      "|   |   | O |\n",
      "+---+---+---+\n",
      "\n",
      "+---+---+---+\n",
      "|   |   |   |\n",
      "+---+---+---+\n",
      "| O | X | X |\n",
      "+---+---+---+\n",
      "|   |   | O |\n",
      "+---+---+---+\n",
      "\n",
      "+---+---+---+\n",
      "|   | X |   |\n",
      "+---+---+---+\n",
      "| O | X | X |\n",
      "+---+---+---+\n",
      "|   |   | O |\n",
      "+---+---+---+\n",
      "\n",
      "+---+---+---+\n",
      "|   | X |   |\n",
      "+---+---+---+\n",
      "| O | X | X |\n",
      "+---+---+---+\n",
      "|   | O | O |\n",
      "+---+---+---+\n",
      "\n",
      "+---+---+---+\n",
      "|   | X | X |\n",
      "+---+---+---+\n",
      "| O | X | X |\n",
      "+---+---+---+\n",
      "|   | O | O |\n",
      "+---+---+---+\n",
      "\n",
      "+---+---+---+\n",
      "|   | X | X |\n",
      "+---+---+---+\n",
      "| O | X | X |\n",
      "+---+---+---+\n",
      "| O | O | O |\n",
      "+---+---+---+\n"
     ]
    }
   ],
   "source": [
    "ttt.reset()\n",
    "tape = play(ttt, policy={1: human_policy, -1: mcts_policy}, print_state=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-10T01:47:07.454217Z",
     "start_time": "2024-01-10T01:46:39.864526Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid decimal literal (66848535.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;36m  Cell \u001B[0;32mIn[17], line 2\u001B[0;36m\u001B[0m\n\u001B[0;31m    1pd.DataFrame(tape)\u001B[0m\n\u001B[0m    ^\u001B[0m\n\u001B[0;31mSyntaxError\u001B[0m\u001B[0;31m:\u001B[0m invalid decimal literal\n"
     ]
    }
   ],
   "source": [
    "\n",
    "1pd.DataFrame(tape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-10T01:22:03.329624Z",
     "start_time": "2024-01-10T01:22:03.325330Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Run Simulations"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-04T04:52:50.184540Z",
     "start_time": "2024-01-04T04:52:50.178227Z"
    }
   },
   "outputs": [],
   "source": [
    "def simulate(round, player_policy_map, start_player=None):\n",
    "    player_policy_map[0] = DummyPolicy(name='Tie')\n",
    "    win_count = {policy.get_name(): 0 for policy in player_policy_map.values()}\n",
    "    for episode in trange(round):\n",
    "        ttt.reset(start_player=start_player or random.choice([-1, 1]))\n",
    "        tape = play(ttt, policy=player_policy_map)\n",
    "        win_count[player_policy_map[ttt.get_winner()].get_name()] += 1\n",
    "    return win_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/10 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c493bbcab1204a29864f8549d6999864"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/10 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "05c21086746f4341b228e7aafa1613ea"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/10 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "abe2b77a9b4041afa04b1501a77f6d75"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/10 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "67f5becf4a5f4be388632486db3e62b2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "   Deterministic Q Table  MinMaxPolicy  Tie              Player -1  \\\n0                      0             0   10           MinMaxPolicy   \n1                      0             0   10           MinMaxPolicy   \n2                      0             0   10  Deterministic Q Table   \n3                      0             0   10  Deterministic Q Table   \n\n                Player 1           Start Player  \n0  Deterministic Q Table  Deterministic Q Table  \n1  Deterministic Q Table           MinMaxPolicy  \n2           MinMaxPolicy           MinMaxPolicy  \n3           MinMaxPolicy  Deterministic Q Table  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Deterministic Q Table</th>\n      <th>MinMaxPolicy</th>\n      <th>Tie</th>\n      <th>Player -1</th>\n      <th>Player 1</th>\n      <th>Start Player</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>10</td>\n      <td>MinMaxPolicy</td>\n      <td>Deterministic Q Table</td>\n      <td>Deterministic Q Table</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>10</td>\n      <td>MinMaxPolicy</td>\n      <td>Deterministic Q Table</td>\n      <td>MinMaxPolicy</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>10</td>\n      <td>Deterministic Q Table</td>\n      <td>MinMaxPolicy</td>\n      <td>MinMaxPolicy</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>10</td>\n      <td>Deterministic Q Table</td>\n      <td>MinMaxPolicy</td>\n      <td>Deterministic Q Table</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# policy_1 = RandomPolicy(name='Random Policy')\n",
    "policy_1 = q_table_policy\n",
    "policy_2 = min_max_policy\n",
    "\n",
    "result_list = []\n",
    "for p1_role, start_player in [[1, 1], [1, -1], [-1, 1], [-1, -1]]:\n",
    "    policy_map = {1*p1_role: policy_1, -1*p1_role: policy_2}\n",
    "    result = simulate(10, policy_map, start_player=start_player)\n",
    "    result['Player -1'] = policy_map[-1].get_name()\n",
    "    result['Player 1'] = policy_map[1].get_name()\n",
    "    result['Start Player'] = policy_map.get(start_player).get_name()\n",
    "    result_list.append(result)\n",
    "pd.DataFrame(result_list)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-04T05:02:35.732763Z",
     "start_time": "2024-01-04T04:58:29.534644Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "1afec097b95f478fbf952ec9418e290f",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
