{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-01T08:58:28.953306Z",
     "start_time": "2024-01-01T08:58:28.930853Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-01T08:58:31.782671Z",
     "start_time": "2024-01-01T08:58:28.952820Z"
    }
   },
   "outputs": [],
   "source": [
    "from src import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-01T08:58:33.114504Z",
     "start_time": "2024-01-01T08:58:31.785287Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from collections import defaultdict\n",
    "from tqdm.auto import tqdm, trange\n",
    "import pickle as pkl\n",
    "from typing import Literal, get_type_hints\n",
    "\n",
    "import itertools as it\n",
    "import more_itertools as mit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-01T08:58:33.140613Z",
     "start_time": "2024-01-01T08:58:33.114686Z"
    }
   },
   "outputs": [],
   "source": [
    "def player_formatter(player: int) -> str:\n",
    "    symbol_mapping = {0: \" \", 1: \"X\", -1: \"O\"}\n",
    "    return symbol_mapping[player]\n",
    "    \n",
    "def state_formatter(state: tuple[int, ...]) -> str:\n",
    "    size = int(len(state) ** 0.5)\n",
    "    formatted_state = \"\\n\"\n",
    "    for i in range(size):\n",
    "        formatted_state += \"+---+---+---+\\n\"\n",
    "        row = state[i*size:(i+1)*size]\n",
    "        formatted_state += \"| \" + \" | \".join(player_formatter(cell)for cell in row) + \" |\\n\"\n",
    "    formatted_state += \"+---+---+---+\"\n",
    "    return formatted_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "+---+---+---+\n",
      "|   |   |   |\n",
      "+---+---+---+\n",
      "|   |   |   |\n",
      "+---+---+---+\n",
      "|   |   |   |\n",
      "+---+---+---+\n"
     ]
    }
   ],
   "source": [
    "ttt = TicTacToe(default_state_formatter=state_formatter)\n",
    "ttt.render()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-01T08:58:33.231677Z",
     "start_time": "2024-01-01T08:58:33.140499Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "q_table_policy = QTablePolicy.load('q_table', lr=0.1, name='Deterministic Q Table')\n",
    "q_table_policy_stochastic = QTablePolicy(q_table_policy.q_table, \n",
    "                                         lr=0.1,\n",
    "                                         stochastic=True,\n",
    "                                         temperature=0.5,\n",
    "                                         name='Stochastic Q Table')\n",
    "human_policy = PromptPolicy(player_formatter)\n",
    "# min_max_policy = MinMaxPolicy(game_cls=TicTacToe)\n",
    "# q_table_policy = QTablePolicy(lr=0.1)\n",
    "# mlp_policy = MLPPolicy(Model(), lr=0.001)\n",
    "# mcts_policy = MCTS(ttt)\n",
    "# mlp_policy = MLPPolicy.load(Model(), 'mlp.pt', lr=0.001)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-01T08:58:33.319678Z",
     "start_time": "2024-01-01T08:58:33.186684Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-01T08:58:35.212496Z",
     "start_time": "2024-01-01T08:58:34.185781Z"
    }
   },
   "outputs": [],
   "source": [
    "def play(ttt, policy=None, print_state=False):\n",
    "    if policy is None:\n",
    "        policy = RandomPolicy()\n",
    "    if not isinstance(policy, dict):\n",
    "        policy = {-1: policy, 1: policy}\n",
    "\n",
    "    tape = [dict(\n",
    "        player=None,\n",
    "        action_space=None,\n",
    "        action=None,\n",
    "        state=ttt.get_state(),\n",
    "        winner=0\n",
    "    )]\n",
    "\n",
    "    while (action_space := ttt.get_actions()) and not ttt.get_winner():\n",
    "        if print_state:\n",
    "            ttt.render()\n",
    "        player = ttt.player\n",
    "        action = ttt.agent_move(policy[player])\n",
    "        state = ttt.get_state()\n",
    "        winner = ttt.get_winner()\n",
    "        tape.append(dict(\n",
    "            player=player,\n",
    "            action_space=action_space,\n",
    "            action=action,\n",
    "            state=state,\n",
    "            winner=winner\n",
    "        ))\n",
    "    if print_state:\n",
    "        ttt.render()\n",
    "\n",
    "    tape.append(dict(\n",
    "        player=None,\n",
    "        action_space=set(),\n",
    "        action=None,\n",
    "        state=ttt.get_state(),\n",
    "        winner=ttt.get_winner()\n",
    "    ))\n",
    "    \n",
    "    return tape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-01T08:58:35.213234Z",
     "start_time": "2024-01-01T08:58:35.177841Z"
    }
   },
   "outputs": [],
   "source": [
    "def swap(state: np.ndarray, option: Literal[1, -1]):\n",
    "    return option * state\n",
    "\n",
    "def flip(state: np.ndarray, option: Literal[True, False]):\n",
    "    return np.fliplr(state) if option else state\n",
    "\n",
    "def rotate(state: np.ndarray, option: Literal[0, 1, 2, 3]):\n",
    "    return np.rot90(state, k=option)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-01T08:58:35.215184Z",
     "start_time": "2024-01-01T08:58:35.178169Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_param_options(fn, param='option'):\n",
    "    return get_type_hints(fn)['option'].__args__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-01T08:58:35.234894Z",
     "start_time": "2024-01-01T08:58:35.193551Z"
    }
   },
   "outputs": [],
   "source": [
    "def transform_state(raw_state, fns, opts):\n",
    "    state = raw_state.reshape([3, 3])\n",
    "    for fn, opt in zip(fns, opts):\n",
    "        state = fn(state, opt)\n",
    "    return state.flatten()\n",
    "\n",
    "def transform_actions(raw_actions, fns, opts):\n",
    "    actions = np.zeros(9)\n",
    "    actions[raw_actions] = 1\n",
    "    actions = transform_state(actions, fns, opts)\n",
    "    return np.nonzero(actions)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-01T08:58:36.089726Z",
     "start_time": "2024-01-01T08:58:36.063568Z"
    }
   },
   "outputs": [],
   "source": [
    "def bellman_equation(policy, reward, state, player, actions):\n",
    "    if not actions:\n",
    "        return reward\n",
    "    return reward + max(policy.get_Q(state, player, action) for action in actions)\n",
    "\n",
    "def replay_episode(tape, policy):\n",
    "    state_list, player_list, action_list, q_list = [], [], [], []\n",
    "    transformations = [swap, flip, rotate]\n",
    "\n",
    "    for pre, cur, nxt in mit.windowed(tape, 3):\n",
    "        raw_start_state = np.array(list(pre['state'])).astype(int)\n",
    "        raw_end_state = np.array(list(nxt['state'])).astype(int)\n",
    "        raw_action = np.array([cur['action']]).astype(int)\n",
    "        raw_action_space = np.array(list(nxt['action_space'])).astype(int)\n",
    "        player = cur['player']\n",
    "        reward = cur['player'] * nxt['winner']\n",
    "        \n",
    "        for opts in it.product(*map(get_param_options, transformations)):\n",
    "            start_state = tuple(transform_state(raw_start_state, transformations, opts).tolist())\n",
    "            end_state = tuple(transform_state(raw_end_state, transformations, opts).tolist())\n",
    "            action = transform_actions(raw_action, transformations, opts).item()\n",
    "            action_space = set(transform_actions(raw_action_space, transformations, opts).tolist())\n",
    "\n",
    "            new_q = bellman_equation(policy, reward, end_state, player, action_space)\n",
    "            state_list.append(start_state)\n",
    "            player_list.append(player)\n",
    "            action_list.append(action)\n",
    "            q_list.append(new_q)\n",
    "\n",
    "    return state_list, player_list, action_list, q_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-01T08:20:30.195212Z",
     "start_time": "2024-01-01T08:20:30.176372Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(policy, episodes, epsilon=0.1):\n",
    "    eps_greedy_policy = EpsilonGreedyPolicy(policy, epsilon=epsilon)\n",
    "    for episode in trange(episodes):\n",
    "        ttt.reset(start_player=random.choice([1, -1]))\n",
    "        tape = play(ttt, policy=eps_greedy_policy)\n",
    "        state_list, player_list, action_list, q_list = replay_episode(tape, policy)\n",
    "        loss = policy.batch_update_Q(state_list, player_list, action_list, q_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-01T07:43:08.744838Z",
     "start_time": "2024-01-01T07:33:10.139453Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/100000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b6ba562d87124d4d8672f969a2c35fee"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train(q_table_policy_stochastic, episodes=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-31T10:20:53.254074Z",
     "start_time": "2023-12-31T10:20:53.124628Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "q_table_policy.save('q_table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "+---+---+---+\n",
      "|   |   |   |\n",
      "+---+---+---+\n",
      "|   |   |   |\n",
      "+---+---+---+\n",
      "|   |   |   |\n",
      "+---+---+---+\n",
      "\n",
      "+---+---+---+\n",
      "|   |   |   |\n",
      "+---+---+---+\n",
      "|   | X |   |\n",
      "+---+---+---+\n",
      "|   |   |   |\n",
      "+---+---+---+\n",
      "\n",
      "+---+---+---+\n",
      "| O |   |   |\n",
      "+---+---+---+\n",
      "|   | X |   |\n",
      "+---+---+---+\n",
      "|   |   |   |\n",
      "+---+---+---+\n",
      "\n",
      "+---+---+---+\n",
      "| O |   | X |\n",
      "+---+---+---+\n",
      "|   | X |   |\n",
      "+---+---+---+\n",
      "|   |   |   |\n",
      "+---+---+---+\n",
      "\n",
      "+---+---+---+\n",
      "| O |   | X |\n",
      "+---+---+---+\n",
      "|   | X |   |\n",
      "+---+---+---+\n",
      "| O |   |   |\n",
      "+---+---+---+\n",
      "\n",
      "+---+---+---+\n",
      "| O |   | X |\n",
      "+---+---+---+\n",
      "| X | X |   |\n",
      "+---+---+---+\n",
      "| O |   |   |\n",
      "+---+---+---+\n",
      "\n",
      "+---+---+---+\n",
      "| O |   | X |\n",
      "+---+---+---+\n",
      "| X | X | O |\n",
      "+---+---+---+\n",
      "| O |   |   |\n",
      "+---+---+---+\n",
      "\n",
      "+---+---+---+\n",
      "| O |   | X |\n",
      "+---+---+---+\n",
      "| X | X | O |\n",
      "+---+---+---+\n",
      "| O | X |   |\n",
      "+---+---+---+\n",
      "\n",
      "+---+---+---+\n",
      "| O | O | X |\n",
      "+---+---+---+\n",
      "| X | X | O |\n",
      "+---+---+---+\n",
      "| O | X |   |\n",
      "+---+---+---+\n",
      "\n",
      "+---+---+---+\n",
      "| O | O | X |\n",
      "+---+---+---+\n",
      "| X | X | O |\n",
      "+---+---+---+\n",
      "| O | X | X |\n",
      "+---+---+---+\n"
     ]
    }
   ],
   "source": [
    "ttt.reset()\n",
    "tape = play(ttt, policy={1: human_policy, -1: q_table_policy}, print_state=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-01T08:21:46.279262Z",
     "start_time": "2024-01-01T08:20:31.895788Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "    player                 action_space  action  \\\n0      NaN                         None     NaN   \n1      1.0  {0, 1, 2, 3, 4, 5, 6, 7, 8}     4.0   \n2     -1.0     {0, 1, 2, 3, 5, 6, 7, 8}     0.0   \n3      1.0        {1, 2, 3, 5, 6, 7, 8}     2.0   \n4     -1.0           {1, 3, 5, 6, 7, 8}     6.0   \n5      1.0              {1, 3, 5, 7, 8}     3.0   \n6     -1.0                 {8, 1, 5, 7}     5.0   \n7      1.0                    {8, 1, 7}     7.0   \n8     -1.0                       {8, 1}     1.0   \n9      1.0                          {8}     8.0   \n10     NaN                           {}     NaN   \n\n                              state  winner  \n0       (0, 0, 0, 0, 0, 0, 0, 0, 0)       0  \n1       (0, 0, 0, 0, 1, 0, 0, 0, 0)       0  \n2      (-1, 0, 0, 0, 1, 0, 0, 0, 0)       0  \n3      (-1, 0, 1, 0, 1, 0, 0, 0, 0)       0  \n4     (-1, 0, 1, 0, 1, 0, -1, 0, 0)       0  \n5     (-1, 0, 1, 1, 1, 0, -1, 0, 0)       0  \n6    (-1, 0, 1, 1, 1, -1, -1, 0, 0)       0  \n7    (-1, 0, 1, 1, 1, -1, -1, 1, 0)       0  \n8   (-1, -1, 1, 1, 1, -1, -1, 1, 0)       0  \n9   (-1, -1, 1, 1, 1, -1, -1, 1, 1)       0  \n10  (-1, -1, 1, 1, 1, -1, -1, 1, 1)       0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>player</th>\n      <th>action_space</th>\n      <th>action</th>\n      <th>state</th>\n      <th>winner</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>NaN</td>\n      <td>None</td>\n      <td>NaN</td>\n      <td>(0, 0, 0, 0, 0, 0, 0, 0, 0)</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.0</td>\n      <td>{0, 1, 2, 3, 4, 5, 6, 7, 8}</td>\n      <td>4.0</td>\n      <td>(0, 0, 0, 0, 1, 0, 0, 0, 0)</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-1.0</td>\n      <td>{0, 1, 2, 3, 5, 6, 7, 8}</td>\n      <td>0.0</td>\n      <td>(-1, 0, 0, 0, 1, 0, 0, 0, 0)</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.0</td>\n      <td>{1, 2, 3, 5, 6, 7, 8}</td>\n      <td>2.0</td>\n      <td>(-1, 0, 1, 0, 1, 0, 0, 0, 0)</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-1.0</td>\n      <td>{1, 3, 5, 6, 7, 8}</td>\n      <td>6.0</td>\n      <td>(-1, 0, 1, 0, 1, 0, -1, 0, 0)</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>1.0</td>\n      <td>{1, 3, 5, 7, 8}</td>\n      <td>3.0</td>\n      <td>(-1, 0, 1, 1, 1, 0, -1, 0, 0)</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>-1.0</td>\n      <td>{8, 1, 5, 7}</td>\n      <td>5.0</td>\n      <td>(-1, 0, 1, 1, 1, -1, -1, 0, 0)</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>1.0</td>\n      <td>{8, 1, 7}</td>\n      <td>7.0</td>\n      <td>(-1, 0, 1, 1, 1, -1, -1, 1, 0)</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>-1.0</td>\n      <td>{8, 1}</td>\n      <td>1.0</td>\n      <td>(-1, -1, 1, 1, 1, -1, -1, 1, 0)</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>1.0</td>\n      <td>{8}</td>\n      <td>8.0</td>\n      <td>(-1, -1, 1, 1, 1, -1, -1, 1, 1)</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>NaN</td>\n      <td>{}</td>\n      <td>NaN</td>\n      <td>(-1, -1, 1, 1, 1, -1, -1, 1, 1)</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(tape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-01T08:22:01.689446Z",
     "start_time": "2024-01-01T08:22:01.634395Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-01T09:12:03.855831Z",
     "start_time": "2024-01-01T09:12:03.828629Z"
    }
   },
   "outputs": [],
   "source": [
    "def simulate(round, player_policy_map, start_player=None):\n",
    "    player_policy_map[0] = DummyPolicy(name='Tie')\n",
    "    win_count = {policy.get_name(): 0 for policy in player_policy_map.values()}\n",
    "    for episode in trange(round):\n",
    "        ttt.reset(start_player=start_player or random.choice([-1, 1]))\n",
    "        tape = play(ttt, policy=player_policy_map)\n",
    "        win_count[player_policy_map[ttt.get_winner()].get_name()] += 1\n",
    "    return win_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/1000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0a0c25e18aeb47a2aff67c6d50e0543f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "349e675322754071a29c2dfee3d0e098"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0e7650712b894d4dbd2849efd4dfb0f6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "069ee757306b4e4e8e2dcdc17fa81cfb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "   Random Policy  Deterministic Q Table  Tie              Player -1  \\\n0              2                    924   74  Deterministic Q Table   \n1              0                    901   99  Deterministic Q Table   \n2              0                    953   47          Random Policy   \n3             34                    891   75          Random Policy   \n\n                Player 1           Start Player  \n0          Random Policy          Random Policy  \n1          Random Policy  Deterministic Q Table  \n2  Deterministic Q Table  Deterministic Q Table  \n3  Deterministic Q Table          Random Policy  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Random Policy</th>\n      <th>Deterministic Q Table</th>\n      <th>Tie</th>\n      <th>Player -1</th>\n      <th>Player 1</th>\n      <th>Start Player</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>924</td>\n      <td>74</td>\n      <td>Deterministic Q Table</td>\n      <td>Random Policy</td>\n      <td>Random Policy</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>901</td>\n      <td>99</td>\n      <td>Deterministic Q Table</td>\n      <td>Random Policy</td>\n      <td>Deterministic Q Table</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>953</td>\n      <td>47</td>\n      <td>Random Policy</td>\n      <td>Deterministic Q Table</td>\n      <td>Deterministic Q Table</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>34</td>\n      <td>891</td>\n      <td>75</td>\n      <td>Random Policy</td>\n      <td>Deterministic Q Table</td>\n      <td>Random Policy</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy_1 = RandomPolicy(name='Random Policy')\n",
    "policy_2 = q_table_policy\n",
    "\n",
    "result_list = []\n",
    "for p1_role, start_player in [[1, 1], [1, -1], [-1, 1], [-1, -1]]:\n",
    "    policy_map = {1*p1_role: policy_1, -1*p1_role: policy_2}\n",
    "    result = simulate(1000, policy_map, start_player=start_player)\n",
    "    result['Player -1'] = policy_map[-1].get_name()\n",
    "    result['Player 1'] = policy_map[1].get_name()\n",
    "    result['Start Player'] = policy_map.get(start_player).get_name()\n",
    "    result_list.append(result)\n",
    "pd.DataFrame(result_list)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-01T09:18:48.746786Z",
     "start_time": "2024-01-01T09:18:46.421964Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "1afec097b95f478fbf952ec9418e290f",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
