{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-06T07:11:00.586025Z",
     "start_time": "2024-02-06T07:11:00.227224Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "from typing import Callable, Optional\n",
    "import time\n",
    "from src import *\n",
    "import pandas as pd\n",
    "import random\n",
    "from tqdm.auto import trange\n",
    "from typing import Literal, get_type_hints\n",
    "import more_itertools as mit\n",
    "import itertools as it"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class TicTacToe_4:\n",
    "    def __init__(self,\n",
    "                 start_player: int = 1,\n",
    "                 default_state_formatter: Callable[[tuple[int, ...]], str] = str,\n",
    "                 size: int = 3):\n",
    "        self.board = np.zeros(size * size, dtype=int)\n",
    "        self.player = start_player\n",
    "        self.default_state_formatter = default_state_formatter\n",
    "        self.action_history = []\n",
    "        self.size = size\n",
    "\n",
    "    @classmethod\n",
    "    def from_state(cls, state: tuple[int, ...], player: int):\n",
    "        obj = TicTacToe()\n",
    "        obj.update_state(state, player)\n",
    "        return obj\n",
    "\n",
    "    def __str__(self):\n",
    "        format_str = '\\n+---+---+---+\\n|{:^size}|{:^size}|{:^size}|' * self.size + '\\n+---+---+---+\\n'\n",
    "        return format_str.format(*np.array([' ', 'X', 'O'])[self.board].tolist())\n",
    "\n",
    "    # TODO: use __str__\n",
    "    def render(self, state_formatter: Optional[Callable[[tuple[int, ...]], str]] = None):\n",
    "        formatter = state_formatter or self.default_state_formatter\n",
    "        print(formatter(self.get_state()), flush=True)\n",
    "\n",
    "    # TODO: optimize\n",
    "    # iterate through all possible lines\n",
    "    def __iter__(self):\n",
    "        # for i in range(self.size):\n",
    "        #     yield self.board[i * self.size: (i + 1) * self.size]\n",
    "        # for i in range(self.size):\n",
    "        #     yield self.board[i::self.size]\n",
    "        # \n",
    "        # yield self.board[::self.size + 1]\n",
    "        # yield self.board[self.size - 1: self.size ** 2 - 1: self.size - 1]\n",
    "        for i in (0, 1, 2, 3):\n",
    "            yield self.board[i], self.board[i + 4], self.board[i + 8], self.board[i + 12]\n",
    "        for i in (0, 4, 8, 10):\n",
    "            yield self.board[i], self.board[i + 1], self.board[i + 2], self.board[i + 3]\n",
    "        for i in (0,):\n",
    "            yield self.board[i], self.board[i + 5], self.board[i + 10], self.board[i + 15]\n",
    "        for i in (3,):\n",
    "            yield self.board[i], self.board[i + 3], self.board[i + 6], self.board[i + 9]\n",
    "\n",
    "    def update_state(self, state: tuple[int, ...], player: int):\n",
    "        self.board = np.array(state, dtype=int)\n",
    "        self.player = player\n",
    "\n",
    "    def get_state(self) -> tuple[int, ...]:\n",
    "        return tuple(self.board.astype(int).tolist())\n",
    "\n",
    "    def get_actions(self):\n",
    "        return set(np.where(self.board == 0)[0].tolist())\n",
    "\n",
    "    def get_winner(self):\n",
    "        start_time = time.time()\n",
    "        for first, second, third, fourth in self:\n",
    "            if first == second == third == fourth != 0:\n",
    "                end_time = time.time()\n",
    "                return first\n",
    "        end_time = time.time()\n",
    "        return 0\n",
    "\n",
    "    def get_player(self):\n",
    "        return self.player\n",
    "\n",
    "    def get_last_player(self):\n",
    "        return -self.player\n",
    "\n",
    "    def is_terminated(self):\n",
    "        return not self.get_actions() or self.get_winner()\n",
    "    def clone(self):\n",
    "        return copy.deepcopy(self)\n",
    "\n",
    "    def move(self, action):\n",
    "        if self.board[action] != 0:\n",
    "            raise Exception(\"Invalid move\")\n",
    "        self.board[action] = self.player\n",
    "        self.player = -self.player\n",
    "        self.action_history.append(action)\n",
    "\n",
    "    def agent_move(self, policy):\n",
    "        best_action = policy(self.get_state(), self.player, self.get_actions())\n",
    "        self.move(best_action)\n",
    "        return best_action\n",
    "\n",
    "    def reset(self, start_player=1):\n",
    "        self.board *= 0\n",
    "        self.player = start_player\n",
    "\n",
    "    def spawn(self, action):\n",
    "        clone = self.clone()\n",
    "        clone.move(action)\n",
    "        return clone\n",
    "\n",
    "    # TODO: value function\n",
    "    def utility(self, player):\n",
    "        if self.is_terminated():\n",
    "            if self.get_winner() == 0:\n",
    "                return 0\n",
    "            return 10 if self.get_winner() == player else -10\n",
    "        return 0\n",
    "\n",
    "    def last_player(self):\n",
    "        return -self.player\n",
    "\n",
    "    def apply_action(self, action):\n",
    "        if self.board[action] != 0:\n",
    "            raise Exception(\"Invalid move\")\n",
    "        self.board[action] = self.player\n",
    "        self.player = -self.player\n",
    "        self.action_history.append(action)\n",
    "\n",
    "    def undo_action(self):\n",
    "        if not self.action_history:\n",
    "            raise Exception(\"No actions to undo\")\n",
    "        last_action = self.action_history.pop()\n",
    "        self.board[last_action] = 0\n",
    "        self.player = -self.player\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-06T07:11:07.308063Z",
     "start_time": "2024-02-06T07:11:07.114485Z"
    }
   },
   "id": "2f3211cb2888fc01",
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def player_formatter(player: int) -> str:\n",
    "    symbol_mapping = {0: \" \", 1: \"X\", -1: \"O\"}\n",
    "    return symbol_mapping[player]\n",
    "\n",
    "def state_formatter(state: tuple[int, ...]) -> str:\n",
    "    size = int(len(state) ** 0.5)\n",
    "    formatted_state = \"\\n\"\n",
    "    for i in range(size):\n",
    "        formatted_state += \"+\" + \"---+\" * size + \"\\n\"\n",
    "        row = state[i*size:(i+1)*size]\n",
    "        formatted_state += \"| \" + \" | \".join(player_formatter(cell)for cell in row) + \" |\\n\"\n",
    "    formatted_state += \"+\" + \"---+\" * size + \"\\n\"\n",
    "    return formatted_state\n",
    "ttt=TicTacToe_4(default_state_formatter=state_formatter, size=4)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-06T07:11:10.402655Z",
     "start_time": "2024-02-06T07:11:10.279466Z"
    }
   },
   "id": "6492766439f059fd",
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from src.policies.q_policies.base_q_policy import BaseQPolicySingle\n",
    "from src.value_functions import BaseValueFunction\n",
    "from typing import Optional\n",
    "\n",
    "\n",
    "class MinMaxPolicy(BaseQPolicySingle):\n",
    "    def __init__(self,\n",
    "                 game_cls,\n",
    "                 heuristic: Optional[BaseValueFunction] = None,\n",
    "                 *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.game_cls = game_cls\n",
    "        self.heuristic = heuristic\n",
    "\n",
    "    def min_max(self, game: TicTacToe, is_max_player, cloned_game, depth):\n",
    "        if game.is_terminated():\n",
    "            winner = game.get_winner()\n",
    "            if winner == cloned_game.player:\n",
    "                return 1\n",
    "            elif winner == 0:\n",
    "                return 0\n",
    "            else:\n",
    "                return -1\n",
    "        if depth == 0:\n",
    "            return self.heuristic.get_V(game.get_state(), cloned_game.player, game.get_actions())\n",
    "\n",
    "        best_score = -float('inf') if is_max_player else float('inf')\n",
    "        for action in game.get_actions():\n",
    "            game.apply_action(action)\n",
    "            score = self.min_max(game, not is_max_player, cloned_game, depth - 1)\n",
    "            game.undo_action()\n",
    "            if (is_max_player and score > best_score) or (not is_max_player and score < best_score):\n",
    "                best_score = score\n",
    "        return best_score\n",
    "\n",
    "    def get_all_Qs(self, state: tuple[int, ...], player: int, action_space: set[int]) -> dict[int, float]:\n",
    "        q_values = {}\n",
    "        for action in action_space:\n",
    "            new_game = self.game_cls.from_state(state, player)\n",
    "            cloned_game = new_game.clone()\n",
    "            new_game.move(action)\n",
    "            score = self.min_max(new_game, False, cloned_game, depth=3)\n",
    "            q_values[action] = score\n",
    "        return q_values\n",
    "\n",
    "    def update_Q(self, state: tuple[int, ...], player: int, action: int, Q: float) -> None:\n",
    "        raise NotImplementedError"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-06T07:11:44.324174Z",
     "start_time": "2024-02-06T07:11:44.160209Z"
    }
   },
   "id": "71873bdc1d94ed97",
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# from src.value_functions.heuristic_4 import Heuristic_4\n",
    "from src.value_functions.heuristic_4_test import Heuristic_4\n",
    "min_max_policy_test = MinMaxPolicy(\n",
    "    game_cls=TicTacToe,\n",
    "    heuristic=Heuristic_4(\n",
    "\n",
    "    )\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-06T07:12:25.770434Z",
     "start_time": "2024-02-06T07:12:25.565415Z"
    }
   },
   "id": "7dfd61279796cb38",
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def play(ttt, policy=None, print_state=False):\n",
    "    if policy is None:\n",
    "        policy = RandomPolicy()\n",
    "    if not isinstance(policy, dict):\n",
    "        policy = {-1: policy, 1: policy}\n",
    "\n",
    "    tape = [dict(\n",
    "        player=None,\n",
    "        action_space=None,\n",
    "        action=None,\n",
    "        state=ttt.get_state(),\n",
    "        winner=0\n",
    "    )]\n",
    "\n",
    "    while (action_space := ttt.get_actions()) and not ttt.get_winner():\n",
    "        if print_state:\n",
    "            ttt.render()\n",
    "        player = ttt.player\n",
    "        action = ttt.agent_move(policy[player])\n",
    "        state = ttt.get_state()\n",
    "        winner = ttt.get_winner()\n",
    "        tape.append(dict(\n",
    "            player=player,\n",
    "            action_space=action_space,\n",
    "            action=action,\n",
    "            state=state,\n",
    "            winner=winner\n",
    "        ))\n",
    "    if print_state:\n",
    "        ttt.render()\n",
    "\n",
    "    tape.append(dict(\n",
    "        player=None,\n",
    "        action_space=set(),\n",
    "        action=None,\n",
    "        state=ttt.get_state(),\n",
    "        winner=ttt.get_winner()\n",
    "    ))\n",
    "\n",
    "    return tape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-06T07:12:29.267522Z",
     "start_time": "2024-02-06T07:12:29.099541Z"
    }
   },
   "id": "78f42dd1aa9d193a",
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def simulate(round, player_policy_map, start_player=None):\n",
    "    player_policy_map[0] = DummyPolicy(name='Tie')\n",
    "    win_count = {policy.get_name(): 0 for policy in player_policy_map.values()}\n",
    "    for episode in trange(round):\n",
    "        ttt.reset(start_player=start_player or random.choice([-1, 1]))\n",
    "        tape = play(ttt, policy=player_policy_map)\n",
    "        win_count[player_policy_map[ttt.get_winner()].get_name()] += 1\n",
    "    return win_count"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-06T07:14:15.902675Z",
     "start_time": "2024-02-06T07:14:15.825643Z"
    }
   },
   "id": "929821922ff7135a",
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/10 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6524a320c392429cb65ee89a9a10dd73"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/10 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "04170a5970ce472cb716731f1a7d545e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/10 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3117353dfe1b4ac2aafde927390e6acf"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/10 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4bf065d62ab3459c97e7ed0a7b1a4846"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "   Random Policy  MinMaxPolicy  Tie      Player -1       Player 1  \\\n0              3             3    4   MinMaxPolicy  Random Policy   \n1              1             5    4   MinMaxPolicy  Random Policy   \n2              2             4    4  Random Policy   MinMaxPolicy   \n3              7             1    2  Random Policy   MinMaxPolicy   \n\n    Start Player  \n0  Random Policy  \n1   MinMaxPolicy  \n2   MinMaxPolicy  \n3  Random Policy  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Random Policy</th>\n      <th>MinMaxPolicy</th>\n      <th>Tie</th>\n      <th>Player -1</th>\n      <th>Player 1</th>\n      <th>Start Player</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3</td>\n      <td>3</td>\n      <td>4</td>\n      <td>MinMaxPolicy</td>\n      <td>Random Policy</td>\n      <td>Random Policy</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>5</td>\n      <td>4</td>\n      <td>MinMaxPolicy</td>\n      <td>Random Policy</td>\n      <td>MinMaxPolicy</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>4</td>\n      <td>4</td>\n      <td>Random Policy</td>\n      <td>MinMaxPolicy</td>\n      <td>MinMaxPolicy</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>7</td>\n      <td>1</td>\n      <td>2</td>\n      <td>Random Policy</td>\n      <td>MinMaxPolicy</td>\n      <td>Random Policy</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy_1 = RandomPolicy(name='Random Policy')\n",
    "# policy_2 = q_table_policy\n",
    "policy_2 = min_max_policy_test\n",
    "result_list = []\n",
    "for p1_role, start_player in [[1, 1], [1, -1], [-1, 1], [-1, -1]]:\n",
    "    policy_map = {1*p1_role: policy_1, -1*p1_role: policy_2}\n",
    "    result = simulate(10, policy_map, start_player=start_player)\n",
    "    result['Player -1'] = policy_map[-1].get_name()\n",
    "    result['Player 1'] = policy_map[1].get_name()\n",
    "    result['Start Player'] = policy_map.get(start_player).get_name()\n",
    "    result_list.append(result)\n",
    "pd.DataFrame(result_list)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-06T07:14:46.172906Z",
     "start_time": "2024-02-06T07:14:16.843565Z"
    }
   },
   "id": "523aa10b5696c296",
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "+---+---+---+---+\n",
      "|   |   |   |   |\n",
      "+---+---+---+---+\n",
      "|   |   |   |   |\n",
      "+---+---+---+---+\n",
      "|   |   |   |   |\n",
      "+---+---+---+---+\n",
      "|   |   |   |   |\n",
      "+---+---+---+---+\n",
      "\n",
      "+---+---+---+---+\n",
      "|   |   |   |   |\n",
      "+---+---+---+---+\n",
      "|   |   |   |   |\n",
      "+---+---+---+---+\n",
      "| X |   |   |   |\n",
      "+---+---+---+---+\n",
      "|   |   |   |   |\n",
      "+---+---+---+---+\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: ''",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[40], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m human_policy \u001B[38;5;241m=\u001B[39m PromptPolicy(player_formatter)\n\u001B[1;32m      2\u001B[0m ttt\u001B[38;5;241m.\u001B[39mreset()\n\u001B[0;32m----> 3\u001B[0m tape \u001B[38;5;241m=\u001B[39m \u001B[43mplay\u001B[49m\u001B[43m(\u001B[49m\u001B[43mttt\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpolicy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m{\u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mhuman_policy\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmin_max_policy_test\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprint_state\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[32], line 19\u001B[0m, in \u001B[0;36mplay\u001B[0;34m(ttt, policy, print_state)\u001B[0m\n\u001B[1;32m     17\u001B[0m     ttt\u001B[38;5;241m.\u001B[39mrender()\n\u001B[1;32m     18\u001B[0m player \u001B[38;5;241m=\u001B[39m ttt\u001B[38;5;241m.\u001B[39mplayer\n\u001B[0;32m---> 19\u001B[0m action \u001B[38;5;241m=\u001B[39m \u001B[43mttt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43magent_move\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpolicy\u001B[49m\u001B[43m[\u001B[49m\u001B[43mplayer\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     20\u001B[0m state \u001B[38;5;241m=\u001B[39m ttt\u001B[38;5;241m.\u001B[39mget_state()\n\u001B[1;32m     21\u001B[0m winner \u001B[38;5;241m=\u001B[39m ttt\u001B[38;5;241m.\u001B[39mget_winner()\n",
      "Cell \u001B[0;32mIn[28], line 84\u001B[0m, in \u001B[0;36mTicTacToe_4.agent_move\u001B[0;34m(self, policy)\u001B[0m\n\u001B[1;32m     83\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21magent_move\u001B[39m(\u001B[38;5;28mself\u001B[39m, policy):\n\u001B[0;32m---> 84\u001B[0m     best_action \u001B[38;5;241m=\u001B[39m \u001B[43mpolicy\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_state\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mplayer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_actions\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     85\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmove(best_action)\n\u001B[1;32m     86\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m best_action\n",
      "File \u001B[0;32m~/Projects/gomoku/src/policies/prompt_policy.py:15\u001B[0m, in \u001B[0;36mPromptPolicy.__call__\u001B[0;34m(self, state, player, actions)\u001B[0m\n\u001B[1;32m     13\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, state: \u001B[38;5;28mtuple\u001B[39m[\u001B[38;5;28mint\u001B[39m, \u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m], player: \u001B[38;5;28mint\u001B[39m, actions: \u001B[38;5;28mset\u001B[39m[\u001B[38;5;28mint\u001B[39m]) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mint\u001B[39m:\n\u001B[1;32m     14\u001B[0m     time\u001B[38;5;241m.\u001B[39msleep(\u001B[38;5;241m0.1\u001B[39m)  \u001B[38;5;66;03m# to prevent the prompt from being printed before the game state\u001B[39;00m\n\u001B[0;32m---> 15\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mint\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;124;43mf\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mEnter action for \u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mformatter\u001B[49m\u001B[43m(\u001B[49m\u001B[43mplayer\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m: \u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mValueError\u001B[0m: invalid literal for int() with base 10: ''"
     ]
    }
   ],
   "source": [
    "human_policy = PromptPolicy(player_formatter)\n",
    "ttt.reset()\n",
    "tape = play(ttt, policy={-1: human_policy, 1: min_max_policy_test}, print_state=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-06T07:15:15.913648Z",
     "start_time": "2024-02-06T07:15:12.464058Z"
    }
   },
   "id": "a12d5d3574f8f003",
   "execution_count": 40
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "2177ff7044010118"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
